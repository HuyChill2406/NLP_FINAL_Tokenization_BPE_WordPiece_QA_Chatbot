{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Hãy xây dựng mô hình để tạo một trợ lý ảo (agent) làm nhiệm vụ chăm sóc khách hàng trong một lĩnh vực nào đó tự bạn chọn, ví dụ:\n",
        "  -Agent chăm sóc, giới thiệu và trả lời câu hỏi khách hàng cho công ty du lịch\n",
        "\n",
        "\n",
        "  Các nhiệm vụ cần làm:\n",
        "  -Thu thập và xây dựng dữ liệu huấn luyện\n",
        "  -Lựa chọn mô hình huấn luyện\n",
        "  -Đánh giá độ chính xác của mô hình\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "PP1ZkCu3Uru8",
        "outputId": "60840e14-289b-48e5-908d-fa47265fe0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Hãy xây dựng mô hình để tạo một trợ lý ảo (agent) làm nhiệm vụ chăm sóc khách hàng trong một lĩnh vực nào đó tự bạn chọn, ví dụ:\\n  -Agent chăm sóc, giới thiệu và trả lời câu hỏi khách hàng cho công ty du lịch\\n\\n\\n  Các nhiệm vụ cần làm:\\n  -Thu thập và xây dựng dữ liệu huấn luyện\\n  -Lựa chọn mô hình huấn luyện\\n  -Đánh giá độ chính xác của mô hình\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset tự làm - lọc dữ liệu các trang báo du lịch Việt Nam"
      ],
      "metadata": {
        "id": "x4L3DaB5Y7fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "kMW6ZJCYvb22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "dLqK7OrUZHtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ],
      "metadata": {
        "id": "_5xwx2TBZJVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/content/drive/MyDrive/datasets_task2.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxcliMKBZN2i",
        "outputId": "0f6597d0-2738-41ad-9e88-6dd6ae3e7070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(606, 7)\n",
            "                        Title  \\\n",
            "0  Tổng quan du lịch Việt Nam   \n",
            "1  Tổng quan du lịch Việt Nam   \n",
            "2  Tổng quan du lịch Việt Nam   \n",
            "3  Tổng quan du lịch Việt Nam   \n",
            "4  Tổng quan du lịch Việt Nam   \n",
            "\n",
            "                                             context  \\\n",
            "0  Ngành Du lịch là ngành kinh tế tổng hợp, gồm n...   \n",
            "1  Ngành Du lịch là ngành kinh tế tổng hợp, gồm n...   \n",
            "2  Ngành du lịch có sự đóng góp to lớn vào tổng s...   \n",
            "3  Ngành du lịch có sự đóng góp to lớn vào tổng s...   \n",
            "4  Ngành du lịch có sự đóng góp to lớn vào tổng s...   \n",
            "\n",
            "                                            question  \\\n",
            "0  Ngành du lịch Việt Nam có phải là ngành kinh t...   \n",
            "1            Ngành du lịch gồm những ngành nghề nào?   \n",
            "2                Ngành du lịch có những đóng góp gì?   \n",
            "3  Ngành du lịch có giúp ích gì cho các ngành khá...   \n",
            "4  Các nhóm nghề trong ngành du lịch là những ngh...   \n",
            "\n",
            "                                             answers  is_impossible  \\\n",
            "0            Ngành Du lịch là ngành kinh tế tổng hợp          False   \n",
            "1  gồm nhiều nhóm ngành nghề liên quan đến nhiệm ...          False   \n",
            "2  Ngành du lịch có sự đóng góp to lớn vào tổng s...          False   \n",
            "3  Du lịch thúc đẩy hỗ trợ các ngành như giao thô...          False   \n",
            "4  Ngành Du lịch hiện có các nhóm nghề chính như ...           True   \n",
            "\n",
            "                                 id  answer_start  \n",
            "0  22e72ae97a885772b5e62b95c9fb554e           0.0  \n",
            "1  ebeb94e61d355cc79c922acab08ea5d2          41.0  \n",
            "2  2e851c0c95675ce0a46944739c4f2bdf           0.0  \n",
            "3  e03ae8c2c2c7546ea65f9b86b8cf9c78         185.0  \n",
            "4  d63a73bb13705a3daabe63b00eb2072e           NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=[\"context\", \"Title\",\n",
        "                      \"is_impossible\", \"id\", \"answer_start\"], axis = 1)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fganCvi_ZQs2",
        "outputId": "0c9dafb8-91e6-4e67-e144-6b3717b7ae2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(606, 2)\n",
            "                                            question  \\\n",
            "0  Ngành du lịch Việt Nam có phải là ngành kinh t...   \n",
            "1            Ngành du lịch gồm những ngành nghề nào?   \n",
            "2                Ngành du lịch có những đóng góp gì?   \n",
            "3  Ngành du lịch có giúp ích gì cho các ngành khá...   \n",
            "4  Các nhóm nghề trong ngành du lịch là những ngh...   \n",
            "\n",
            "                                             answers  \n",
            "0            Ngành Du lịch là ngành kinh tế tổng hợp  \n",
            "1  gồm nhiều nhóm ngành nghề liên quan đến nhiệm ...  \n",
            "2  Ngành du lịch có sự đóng góp to lớn vào tổng s...  \n",
            "3  Du lịch thúc đẩy hỗ trợ các ngành như giao thô...  \n",
            "4  Ngành Du lịch hiện có các nhóm nghề chính như ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data"
      ],
      "metadata": {
        "id": "eoTuOD4ZbI0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGt_kVrIZSxc",
        "outputId": "0022194a-956d-43bb-f89b-0956d967b23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question    0\n",
              "answers     2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with NaN values\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "OrXUS7ajZXuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the NaN values are handled\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRumsFmuZYiC",
        "outputId": "cc243a0a-1f14-4ed9-b1cf-62ff83903fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question    0\n",
              "answers     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training data and labels\n",
        "train_data = df['question'].tolist()\n",
        "train_labels = df['answers'].tolist()"
      ],
      "metadata": {
        "id": "xfSmixcEZdWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(train_labels)"
      ],
      "metadata": {
        "id": "AbTYayu1ZfDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize"
      ],
      "metadata": {
        "id": "QVyOHI33bLUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the training data\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data)\n",
        "train_sequences = keras.preprocessing.sequence.pad_sequences(train_sequences)"
      ],
      "metadata": {
        "id": "IhjzSu3-ZgH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and compile the model\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Embedding(len(tokenizer.word_index) + 1, 100, \\\n",
        "                                 input_length=train_sequences.shape[1]))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "model.add(keras.layers.Dense(len(train_labels), activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \\\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dFPLikqMZh-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaVgacihE6-9",
        "outputId": "e22c7441-658e-42d0-80f7-450adcc61c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 38, 100)           76600     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3800)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                243264    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 604)               39260     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 359124 (1.37 MB)\n",
            "Trainable params: 359124 (1.37 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_sequences,\\\n",
        "                                                    encoded_labels,\\\n",
        "                                                    test_size = 0.3, \\\n",
        "                                                    random_state = 42)"
      ],
      "metadata": {
        "id": "G65vM4VBZnoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "0ueio2ombNuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eXE5zWQZsFs",
        "outputId": "6c66cd27-1ebd-47ac-d087-9db2aa146d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "14/14 [==============================] - 1s 7ms/step - loss: 6.4126 - accuracy: 0.0047\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 6.3677 - accuracy: 0.0261\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 6.2757 - accuracy: 0.0261\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 6.1493 - accuracy: 0.0261\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 6.0461 - accuracy: 0.0261\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 5.9750 - accuracy: 0.0261\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 5.9180 - accuracy: 0.0261\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 5.8552 - accuracy: 0.0261\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 5.7847 - accuracy: 0.0261\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5.6883 - accuracy: 0.0284\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 5.5773 - accuracy: 0.0355\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 5.4438 - accuracy: 0.0545\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 5.2838 - accuracy: 0.0569\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 5.0874 - accuracy: 0.0853\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 4.8678 - accuracy: 0.1137\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 4.6152 - accuracy: 0.1398\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 4.3176 - accuracy: 0.1777\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 4.0057 - accuracy: 0.2796\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 3.6736 - accuracy: 0.3531\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 3.3188 - accuracy: 0.5379\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 2.9655 - accuracy: 0.5806\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 2.6241 - accuracy: 0.6256\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 2.2628 - accuracy: 0.7299\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.9317 - accuracy: 0.7986\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.6813 - accuracy: 0.7749\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1.4127 - accuracy: 0.8436\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 1.1953 - accuracy: 0.9076\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 1.0048 - accuracy: 0.9076\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8548 - accuracy: 0.9384\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7281 - accuracy: 0.9502\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6318 - accuracy: 0.9455\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5454 - accuracy: 0.9597\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.9526\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.9716\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.9716\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3249 - accuracy: 0.9834\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2753 - accuracy: 0.9858\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2430 - accuracy: 0.9882\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.9739\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2054 - accuracy: 0.9929\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9953\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.9953\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1469 - accuracy: 0.9929\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1317 - accuracy: 0.9976\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.9953\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1264 - accuracy: 0.9929\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1035 - accuracy: 0.9976\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9976\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0946 - accuracy: 0.9953\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d113bd978e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print(f'Vocabulary size : {VOCAB_SIZE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFcvqOvJDjUr",
        "outputId": "a0f7c837-d696-421e-ac1c-a6a982918715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size : 766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate responses\n",
        "def generate_response(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    sequence = keras.preprocessing.sequence.pad_sequences(sequence, maxlen = train_sequences.shape[1])\n",
        "    prediction = model.predict(sequence)\n",
        "    predicted_label = np.argmax(prediction)\n",
        "    response = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    return response"
      ],
      "metadata": {
        "id": "ML7o2COzZtYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "PQJOaj7PbPY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Welcome to the Q&A bot! Type your question or 'bye' to exit.\")\n",
        "print()\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'bye':\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "    else:\n",
        "        # Generate response using the previously defined function\n",
        "        predicted_answer = generate_response(user_input)\n",
        "        print(\"Chatbot:\", predicted_answer)\n",
        "        print(\"-\" * 100)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J5PmD3nT-O_",
        "outputId": "187319b6-d947-4c75-ab15-008bd49881a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Q&A bot! Type your question or 'bye' to exit.\n",
            "\n",
            "You: Nhiệt độ trung bình ở Sapa là bao nhiêu?\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Chatbot: nhiệt độ bình trung hàng năm ở Sa Pa là 15,4oC, nhiệt độ trung bình từ 18-20oC vào tháng mùa hè, vào các tháng mùa đông 10-12oC. Nhiệt độ thấp nhất vào tháng 1 là 0oC (đặc biệt có những năm xuống tới - 3,2oC)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Cảng Cái Lân ở Hạ Long là địa điểm gì?\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Chatbot: Cảng Cái Lân là nhuyễn nước sâu nhất miền Bắc, nằm ở phía Bắc thành phố Hạ Long, gần Cửa Lục. Cảng Cái Lân với vị trí thuận lợi trong vùng vịnh kín, nước sâu, suối vào ít bị sa bồi, mới nước sâu hơn – 10m và khu nước trước bến sâu – 13m. Cảng có 7 cầu mã, được phép tiếp tục nhận tàu có tải trọng trên 70.000 tấn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Thiền viện Trúc Lâm nằm ở đâu?\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Chatbot: Địa chỉ chùa Hộ Quốc tọa lạc tại ấp Suối Lớn, thuộc địa phận xã Dương Tơ, thành phố Phú Quốc, Kiên Giang. Ngôi chùa còn có tên gọi đặc biệt khác là thiền viện Trúc Lâm Hộ Quốc. Địa chỉ này khá gần với sân bay Phú Quốc, chỉ cách khoảng 10km và cách trung tâm phường Dương Đông khoảng 20km\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Làng cổ Đường Lâm nằm ở đâu?\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Chatbot: Làng cổ Đường Lâm nằm cách 44 km về phía tây của trung tâm thành phố Hà Nội, thuộc thị xã Sơn Tây, Hà Nội\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Nguyên liệu để làm ra trà sen Tây Hồ là gì?\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Chatbot: được làm từ lá chè xanh khô ngâm trong nước sen để hút hương hoa sen\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Đảo Phú Quốc gồm các khu vực nào?\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Chatbot: đảo Phú Quốc lớn nhất được chia thành bắc đảo và nam đảo. Thị trấn Dương Đông nằm ở trung tâm\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Văn Miếu Quốc Tử Giám được xây dựng khi nào?\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Chatbot: được xây dựng vào năm 1076 dưới thời vua Lý Nhân Tông\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Làm sao để đến được bản Cát Cát ở Sapa?\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Chatbot: none\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Nhà thùng nước mắm Khải Hoàn ở đâu?\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Chatbot: Toạ lạc ở số 11 Hùng Vương, Dương Đông, Phú Quốc, Kiên Giang\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Có nên tắm biển tại Bãi Sao không?\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Chatbot: Nước biển tại Bãi Sao không quá sâu, lại có bãi rộng nên tương đối an toàn ngay cả với gia đình có trẻ nhỏ đi du lịch Phú Quốc\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: Bánh mì ở Hội An có gì đặc biệt?\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Chatbot: Bánh mì ở đây ăn một ổ lo không một buổi bởi chất lượng nhân không chê vào đâu được, pate, thịt, trứng chả, đầy ắp với nước sốt chứa chan hương vị Hội An\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You:  Địa chỉ bán bánh căn ngon ở Nha Trang\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Chatbot: Địa chỉ tham khảo: Quán Quốc Anh: Khu phố I, thị trấn Dương Đông, Quán Lê Giang: 289 Trần Hưng Đạo, thị trấn Dương Đông\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "You: bye\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "6XK5zcmpbQy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcNB31QAT-Mu",
        "outputId": "6472f80c-4b4b-4b93-cc16-57bebf0d6aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step\n",
            "Accuracy: 0.01098901098901099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU Score"
      ],
      "metadata": {
        "id": "wsJB9sEBDTSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bleu_score(y_test, y_pred, label_encoder):\n",
        "    bleu_scores = []\n",
        "    smooth = SmoothingFunction().method1\n",
        "    for true, pred in zip(y_test, y_pred):\n",
        "        reference = [label_encoder.inverse_transform([true])[0].split()]\n",
        "        candidate = label_encoder.inverse_transform([pred])[0].split()\n",
        "        bleu_score = sentence_bleu(reference, candidate, smoothing_function=smooth)\n",
        "        bleu_scores.append(bleu_score)\n",
        "    return np.mean(bleu_scores)\n",
        "\n",
        "# Example usage (assuming y_test, y_pred, and label_encoder are defined)\n",
        "average_bleu_score = calculate_bleu_score(y_test, y_pred, label_encoder)\n",
        "print(\"Average BLEU Score:\", average_bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD3ZV8KrFO6Z",
        "outputId": "5bf15e90-451b-4871-9f07-0ea54394471e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 0.008809940291908298\n"
          ]
        }
      ]
    }
  ]
}